{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import json \n",
      "import numpy as np\n",
      "import cPickle\n",
      "import utils\n",
      "reload(utils)\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.cross_validation import KFold, cross_val_score\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from pyrallel import mmap_utils, model_selection\n",
      "from sklearn.cluster import MiniBatchKMeans\n",
      "from sklearn.metrics.pairwise import safe_sparse_dot\n",
      "from sklearn.preprocessing import normalize\n",
      "from scipy.spatial import distance"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## text data preparation - merging title and body \n",
      "- title is hard to dealt with when alone"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.read_csv('data/train.tsv', sep='\\t', na_values=['?', 'null'])\n",
      "#data = pd.read_csv('data/test.tsv', sep='\\t', na_values=['?', 'null'])\n",
      "data['boilerplate'] = data['boilerplate'].apply(json.loads)\n",
      "data['title'] = data['boilerplate'].apply(lambda x: x.get('title', ''))\n",
      "data['body'] = data['boilerplate'].apply(lambda x: x.get('body', ''))\n",
      "data.loc[pd.isnull(data.title), 'title'] = ''\n",
      "data.loc[pd.isnull(data.body), 'body'] = ''\n",
      "data['text'] = data.apply(lambda r: ' '.join(r.loc[['title', 'body']]), axis = 1)\n",
      "data = data.loc[data.text != ' ',:] ## one element excluded fro training, none for testing\n",
      "print data.shape\n",
      "print sum(pd.isnull(data.text))\n",
      "print sum(data.text == ' ')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(7394, 30)\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text_data = np.asarray(data.loc[:, 'text'])\n",
      "label_data = np.asarray(data.loc[:, 'label'])\n",
      "n_samples = text_data.shape[0]\n",
      "print text_data.shape, label_data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(7394,) (7394,)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## simple bag of words"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## tfidf with a linear (MNB) classifier\n",
      "\n",
      "tfidf = TfidfVectorizer(encoding = 'unicode', max_df = 0.5, \n",
      "                        stop_words='english')\n",
      "print tfidf\n",
      "nb = MultinomialNB()\n",
      "cv = KFold(n_samples, n_folds=3, shuffle=True, random_state=0)\n",
      "clf = Pipeline(steps = [\n",
      "    ('tfidf', tfidf),\n",
      "    ('nb', nb)\n",
      "])\n",
      "print cross_val_score(clf, text_data, label_data, cv = cv, n_jobs=-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "TfidfVectorizer(analyzer=word, binary=False, charset=None, charset_error=None,\n",
        "        decode_error=strict, dtype=<type 'numpy.int64'>, encoding=unicode,\n",
        "        input=content, lowercase=True, max_df=0.5, max_features=None,\n",
        "        min_df=1, ngram_range=(1, 1), norm=l2, preprocessor=None,\n",
        "        smooth_idf=True, stop_words=english, strip_accents=None,\n",
        "        sublinear_tf=False, token_pattern=(?u)\\b\\w\\w+\\b, tokenizer=None,\n",
        "        use_idf=True, vocabulary=None)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.78823529  0.79756592  0.78936688]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## hashing with a linear (MNB) classifier with non-negative features\n",
      "\n",
      "hasher = HashingVectorizer(encoding = 'unicode', stop_words='english', non_negative=True)\n",
      "print hasher\n",
      "nb = MultinomialNB()\n",
      "cv = KFold(n_samples, n_folds=3, shuffle=True, random_state=0,)\n",
      "clf = Pipeline(steps = [\n",
      "    ('hasher', hasher),\n",
      "    ('nb', nb)\n",
      "])\n",
      "%time print cross_val_score(clf, text_data, label_data, cv = cv, n_jobs=-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "HashingVectorizer(analyzer=word, binary=False, charset=None,\n",
        "         charset_error=None, decode_error=strict,\n",
        "         dtype=<type 'numpy.float64'>, encoding=unicode, input=content,\n",
        "         lowercase=True, n_features=1048576, ngram_range=(1, 1),\n",
        "         non_negative=True, norm=l2, preprocessor=None, stop_words=english,\n",
        "         strip_accents=None, token_pattern=(?u)\\b\\w\\w+\\b, tokenizer=None)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.77931034  0.79148073  0.78571429]\n",
        "CPU times: user 140 ms, sys: 93.3 ms, total: 234 ms\n",
        "Wall time: 5.17 s\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## hasher with a nonlinear (SVC) classifier with zero-mean features\n",
      "## non_negative = True/False does not really matter here\n",
      "hasher = HashingVectorizer(encoding = 'unicode', stop_words='english', non_negative=True)\n",
      "\n",
      "svc = SVC(random_state=0, C = 10, gamma = 0.01)\n",
      "clf = Pipeline(steps = [\n",
      "    ('hasher', hasher),\n",
      "    ('svc', svc)\n",
      "])\n",
      "\n",
      "cv = KFold(n_samples, n_folds=3, shuffle=True, random_state=0)\n",
      "%time print cross_val_score(clf, text_data, label_data, cv = cv, n_jobs = -1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.77525355  0.80608519  0.79383117]\n",
        "CPU times: user 162 ms, sys: 99.8 ms, total: 262 ms\n",
        "Wall time: 33.9 s\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## tfidf with a nonlinear (SVC) classifier\n",
      "\n",
      "tfidf = TfidfVectorizer(encoding = 'unicode', max_df = 0.5,\n",
      "                        stop_words='english')\n",
      "\n",
      "svc = SVC(random_state=0, C = 10, gamma = 0.01)\n",
      "clf = Pipeline(steps = [\n",
      "    ('tfidf', tfidf),\n",
      "    ('svc', svc)\n",
      "])\n",
      "\n",
      "cv = KFold(n_samples, n_folds=3, shuffle=True, random_state=0)\n",
      "print cross_val_score(clf, text_data, label_data, cv = cv, n_jobs = -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.77241379  0.8040568   0.79220779]\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**When using bag of words, HashVectorizer and TfidfVectorizer dont seem to have a significant difference. The best performance of SVC-nonlinear is close to a linear model such as MNB**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## bag-of-words with cluster based kernel expansion"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#tfidf = TfidfVectorizer(encoding = 'unicode', max_df = 0.5,\n",
      "#                        stop_words='english')\n",
      "\n",
      "## hasher with MiniBatchKMeans will run out of memory with default feature number\n",
      "hasher = HashingVectorizer(encoding = 'unicode', stop_words='english', non_negative=True, n_features=100000)\n",
      "X = hasher.fit_transform(text_data)\n",
      "print type(X), X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'scipy.sparse.csr.csr_matrix'> (7394, 100000)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## SOFT Thresholding with KMEANS\n",
      "kmeans = MiniBatchKMeans(n_clusters=1500, max_iter=10, batch_size=100, verbose=0, init='random',\n",
      "                         reassignment_ratio=0, compute_labels=True, random_state=0, n_init=1)\n",
      "kmeans.fit(X)\n",
      "\n",
      "## seems that normalize does not matter, even to SVC\n",
      "## thr = 'mean' or 'median' does NOT matter\n",
      "S = utils.soft_threshold(X, kmeans.cluster_centers_, thr = 'mean')\n",
      "print S.shape\n",
      "\n",
      "nb = MultinomialNB()\n",
      "cv = KFold(n_samples, n_folds=3, shuffle=True, random_state=0)\n",
      "print cross_val_score(nb, S, label_data, cv = cv, n_jobs = -1, )\n",
      "\n",
      "svc = SVC(random_state=0, C = 10, gamma = 0.01)\n",
      "cv = KFold(n_samples, n_folds=3, shuffle=True, random_state=0)\n",
      "%time print cross_val_score(svc, S, label_data, cv = cv, n_jobs = -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(7394, 1500)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Library/Python/2.7/site-packages/sklearn/cluster/k_means_.py:1161: RuntimeWarning: init_size=300 should be larger than k=1500. Setting it to 3*k\n",
        "  init_size=init_size)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.77484787  0.78904665  0.77637987]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.7801217   0.80324544  0.79991883]\n",
        "CPU times: user 247 ms, sys: 339 ms, total: 586 ms\n",
        "Wall time: 42.8 s\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## EXPENSIVE TO RUN\n",
      "trees = ExtraTreesClassifier()\n",
      "param_grid = {\n",
      "    'n_estimators': [500],\n",
      "    'max_features': [100]\n",
      "}\n",
      "cv = KFold(n_samples, n_folds=3, shuffle=True, random_state=0)\n",
      "gs = GridSearchCV(trees, param_grid, n_jobs = -1, cv = cv)\n",
      "%time gs.fit(S, label_data)\n",
      "print gs.best_params_\n",
      "print gs.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 4min 13s, sys: 503 ms, total: 4min 14s\n",
        "Wall time: 6min 59s\n",
        "{'max_features': 100, 'n_estimators': 500}\n",
        "0.787665674872\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
        "  DeprecationWarning)\n",
        "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
        "  DeprecationWarning)\n",
        "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
        "  DeprecationWarning)\n",
        "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
        "  DeprecationWarning)\n",
        "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
        "  DeprecationWarning)\n",
        "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
        "  DeprecationWarning)\n",
        "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
        "  DeprecationWarning)\n",
        "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
        "  DeprecationWarning)\n",
        "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/nose/util.py:14: DeprecationWarning: The compiler package is deprecated and removed in Python 3.x.\n",
        "  from compiler.consts import CO_GENERATOR\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## SOFT Thresholding with random sampling\n",
      "selection = np.arange(n_samples)\n",
      "np.random.shuffle(selection)\n",
      "centers = X[selection[:1500]]\n",
      "print centers.shape, centers.dtype\n",
      "\n",
      "## seems that normalize does not matter, even to SVC\n",
      "## thr = 'mean' or 'median' does NOT matter\n",
      "S = utils.soft_threshold(X, centers, thr = 'median')\n",
      "print S.shape\n",
      "\n",
      "nb = MultinomialNB()\n",
      "cv = KFold(n_samples, n_folds=3, shuffle=True, random_state=0)\n",
      "print cross_val_score(nb, S, label_data, cv = cv, n_jobs = -1, )\n",
      "\n",
      "svc = SVC(random_state=0, C = 10, gamma = 0.01)\n",
      "cv = KFold(n_samples, n_folds=3, shuffle=True, random_state=0)\n",
      "%time print cross_val_score(svc, S, label_data, cv = cv, n_jobs = -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1500, 100000) float64\n",
        "(7394, 1500)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.77565923  0.78701826  0.77678571]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.7821501   0.80851927  0.80357143]\n",
        "CPU times: user 251 ms, sys: 339 ms, total: 589 ms\n",
        "Wall time: 43.3 s\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**By using poor-man kernel expansion (kmeans or random-sampling) The dimension of bag of words can be significnatly reduced from about 100k to 1500, and yet no significant performance loss is observed, but no boost observed either - though NOW IT IS POSSIBLE to build dense models such as extraTrees**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## kernel-expansion stacked with sparse filtering"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sparse_filtering import SparseFilter\n",
      "sf = SparseFilter(n_vis = 1500, n_hid = 1000)\n",
      "%time sf.fit(S, maxfun = 200, iprint = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
        "  DeprecationWarning)\n",
        "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
        "  DeprecationWarning)\n",
        "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
        "  DeprecationWarning)\n",
        "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
        "  DeprecationWarning)\n",
        "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
        "  DeprecationWarning)\n",
        "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
        "  DeprecationWarning)\n",
        "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
        "  DeprecationWarning)\n",
        "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
        "  DeprecationWarning)\n",
        "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/nose/util.py:14: DeprecationWarning: The compiler package is deprecated and removed in Python 3.x.\n",
        "  from compiler.consts import CO_GENERATOR\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "SparseFilter(n_hid=1000, n_vis=1500)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Z = sf.transform(S)\n",
      "print Z.shape, type(Z)\n",
      "cPickle.dump((Z, label_data), open('tmp/sparse_filter.pkl', 'w'))\n",
      "!ls tmp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(7394, 1000) <type 'numpy.ndarray'>\n",
        "sparse_filter.pkl\r\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Z, label_data = cPickle.load(open('tmp/sparse_filter.pkl', 'r'))\n",
      "Z = normalize(Z)\n",
      "print Z.shape, label_data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(7394, 1000) (7394,)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "n_samples = Z.shape[0]\n",
      "svc = SVC(random_state=0, C = 10, gamma = 0.01)\n",
      "cv = KFold(n_samples, n_folds=3, shuffle=True, random_state=0)\n",
      "%time print cross_val_score(svc, Z, label_data, cv = cv, n_jobs = -1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.78336714  0.7979716   0.79788961]\n",
        "CPU times: user 199 ms, sys: 305 ms, total: 503 ms\n",
        "Wall time: 28.2 s\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import SGDClassifier\n",
      "sgd = SGDClassifier(loss = 'log', penalty='elasticnet', shuffle = True, )\n",
      "param_grid = {\n",
      "    'alpha': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
      "    'l1_ratio': [0.1, 0.2, 0.5, 0.7]\n",
      "}\n",
      "gs = GridSearchCV(sgd, param_grid, n_jobs=-1, cv = cv)\n",
      "%time gs.fit(Z, label_data)\n",
      "print gs.best_params_\n",
      "print gs.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 4.15 s, sys: 5.72 s, total: 9.87 s\n",
        "Wall time: 14.1 s\n",
        "{'alpha': 0.0001, 'l1_ratio': 0.1}\n",
        "0.795915607249\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}