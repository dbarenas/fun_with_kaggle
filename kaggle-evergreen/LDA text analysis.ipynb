{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import json\n",
      "import numpy as np\n",
      "import pylab as pl\n",
      "from gensim import matutils\n",
      "from gensim import models\n",
      "from gensim import corpora\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from IPython.parallel import Client\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.cross_validation import cross_val_score, KFold\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from scipy.sparse import csr_matrix\n",
      "\n",
      "%pylab inline --no-import\n",
      "client = Client()\n",
      "print len(client)\n",
      "lb_view = client.load_balanced_view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n",
        "4\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.read_csv('data/train.tsv', sep='\\t', na_values=['?', 'null'])\n",
      "#data = pd.read_csv('data/test.tsv', sep='\\t', na_values=['?', 'null'])\n",
      "data['boilerplate'] = data['boilerplate'].apply(json.loads)\n",
      "data['title'] = data['boilerplate'].apply(lambda x: x.get('title', ''))\n",
      "data['body'] = data['boilerplate'].apply(lambda x: x.get('body', ''))\n",
      "data.loc[pd.isnull(data.title), 'title'] = ''\n",
      "data.loc[pd.isnull(data.body), 'body'] = ''\n",
      "data['text'] = data.apply(lambda r: ' '.join(r.loc[['title', 'body']]), axis = 1)\n",
      "data = data.loc[data.text != ' ',:] ## one element excluded fro training, none for testing\n",
      "print data.shape\n",
      "print sum(pd.isnull(data.text))\n",
      "print sum(data.text == ' ')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(7394, 30)\n",
        "0\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text_data = np.asarray(data.loc[:, 'text'])\n",
      "label_data = np.asarray(data.loc[:, 'label'])\n",
      "n_samples = text_data.shape[0]\n",
      "print text_data.shape, label_data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(7394,) (7394,)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## build gensim corpus from tfidf model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_samples = text_data.shape[0]\n",
      "n_topics = 1000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf = TfidfVectorizer(encoding = 'unicode', max_df = 0.5, \n",
      "                        stop_words='english')\n",
      "vectorize = tfidf.build_analyzer()\n",
      "dictionary = corpora.Dictionary([vectorize(r) for r in text_data])\n",
      "dictionary.save('tmp/train.dict')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = [dictionary.doc2bow(vectorize(doc)) for doc in text_data]\n",
      "corpora.BleiCorpus.serialize('tmp/train_corpus', corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time lda = models.LdaModel(corpus=corpus, num_topics=n_topics, id2word=dictionary, alpha = 1, chunksize = 500, passes = 3, )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 26min 2s, sys: 4min 32s, total: 30min 34s\n",
        "Wall time: 29min 40s\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda[corpus[1000]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "[(210, 0.058914244019211699), (403, 0.012341376911992216)]"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### check learned lda"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda.save('tmp/lda')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda = models.LdaModel.load('tmp/lda')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "S = np.zeros((n_samples, n_topics))\n",
      "for i, doc in enumerate(corpus):\n",
      "    for topic, wt in lda[doc]:\n",
      "        S[i, topic] = wt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Z = csr_matrix(S)\n",
      "print Z.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(7394, 1000)\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sgd = SGDClassifier(loss = 'log', penalty='elasticnet', random_state=0, )\n",
      "cv = KFold(n_samples, n_folds=3, shuffle=True, random_state=0)\n",
      "param_grid = {\n",
      "    'alpha': [1e-5, 1e-4, 1e-3],\n",
      "    'l1_ratio': [0.1, 0.2, 0.5]\n",
      "}\n",
      "gs = GridSearchCV(sgd, param_grid, n_jobs=-1, cv = cv)\n",
      "%time gs.fit(Z, label_data)\n",
      "print gs.best_params_\n",
      "print gs.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 31.6 ms, sys: 21.4 ms, total: 53 ms\n",
        "Wall time: 136 ms\n",
        "{'alpha': 1e-05, 'l1_ratio': 0.1}\n",
        "0.586691912361\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}