str(titanic)
with(titanic, table(Class, Survived))
with(titanic, xtab(Class ~ Survived))
with(titanic, xtabs(Class ~ Survived))
with(titanic, xtabs(Class ~ Survived))
with(titanic, xtabs(as.numeric(Class) ~ as.numeric(Survived)))
?xtabs
xtabs(Survived ~ Class + Sex, data = titanic)
with(titanic, table(Sex, Survived))
head(df)
titanic <- foreach(i=1:4, .combine='cbind', .inorder=F)%dopar%{rep(as.character(df[, i]), df$Freq)}
head(titanic)
titanic <- as.data.frame(titanic)
head(titanic)
names(titanic) <- names(df)[1:4]
summary(titanic)
xtabs(Survived ~ Class, data = titanic)
with(titanic, table(Class, Survived))
?tapply
nrow(titanic)
hist(Sex ~ Survived, data = titanic)
library('randomForest')
test.index <- sample(1:nrow(titanic), size=nrow(titanic)/5, replace=F)
test.data <- titanic[test.index, ]
train.data <- titanic[-test.index, ]
rf <- randomForest(train.data, ntree=100)
?randomForest::
?randomForest
plot(rf)
rf <- randomForest(Survived ~ .,data = train.data, ntree=100)
plot(rf)
summary(rf)
yhat <- predict(rf, newdata = test.data)
table(yhat, test.data$Survived)
rf <- randomForest(Survived ~ .,data = train.data, ntree=100, sampsize=c(50, 50))
yhat <- predict(rf, newdata = test.data)
table(yhat, test.data$Survived)
rf <- randomForest(Survived ~ .,data = train.data, ntree=100, sampsize=c(100, 100))
yhat <- predict(rf, newdata = test.data)
table(yhat, test.data$Survived)
rf <- randomForest(Survived ~ .,data = train.data, ntree=100, sampsize=c(200, 100))
yhat <- predict(rf, newdata = test.data)
table(yhat, test.data$Survived)
rf <- randomForest(Survived ~ .,data = train.data, ntree=100, sampsize=c(500, 500))
yhat <- predict(rf, newdata = test.data)
rf <- randomForest(Survived ~ .,data = train.data, ntree=100, sampsize=c(500, 500))
yhat <- predict(rf, newdata = test.data)
table(yhat, test.data$Survived)
library(arules)
install.packages('arules')
library('arules')
rules <- apriori(titanic)
inspect(rules)
rules <- apriori(titanic, parameter=list(minlen=2, supp=0.005, conf=0.8),appearance=list(rhs=c("Survived=No", "Survived=Yes"), default="lhs"))
rules.sorted <- sort(rules, by="lift")
inspect(rules.sorted)
plot(rules, method ='grouped')
install.packages('arulesViz')
library(arulesViz)
plot(rules, method='grouped')
plot(rules, method='graph')
install.packages(c('twitterR', 'wordcloud'))
library(c('twitterR', 'wordcloud', 'tm'))
library(twitterR)
install.packages(twitteR)
install.packages('twitteR')
library('twitteR')
library(tm)
library(wordcloud)
rdmTweets <- userTimeline('rdatamining', n = 200)
summary(rdmTweets)
rdmTweets[11:15]
str(rdmTweets)
rdmTweets[11:15]
?tweetR
??twittR
str(rdmTweets[[i]])
str(rdmTweets[[1]])
?do.call
lapply(rdmTweets,as.data.frame)[[1]]
foreach(i = 1:length(rdmTweets), .combine='rbind', .inorder=T) %dopar% {as.data.frame(rdmTweets[i,])}
foreach(i = 1:length(rdmTweets), .combine='rbind', .inorder=T) %dopar% {as.data.frame(rdmTweets[[i]])}
df <- foreach(i = 1:length(rdmTweets), .combine='rbind', .inorder=T) %dopar% {as.data.frame(rdmTweets[[i]])}
dim(df)
str(df)
summary(df)
corpus <- Corpus(VectorSource(df$text))
summary(corpus)
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, FUN=function(s){gsub("http://.*", "", s)})
c(1) not %in% c(1, 2, 3)
c(1) %notin% c(1, 2, 3)
c(1) %in% c(1, 2, 3)
not(c(1) %in% c(1, 2, 3))
-(c(1) %in% c(1, 2, 3))
!(c(1) %in% c(1, 2, 3))
corpus <- tm_filter(corpus, FUN=function(s){!(s %in% stopwords('english'))})
corpus
corpus[[1]]
corpus[[2]]
corpus <- tm_map(corpus, removeWords, stopwords('english'))
stemmed <- tm_map(corpus, stemDocument)
install.packages('Snowball')
install.packages('Snowball')
stemmed <- tm_map(corpus, stemDocument)
install.packages('rJava')
install.packages("rJava")
install.packages("RWeka")
install.packages("RWeka")
install.packages("RWekajars")
install.packages("RWekajars")
library(tm)
update.pacakges()
update.packages()
stemmed <- tm_map(corpus, stemDocument)
inspect(stemmed[1:5])
install.pacakges('rJava')
install.packages('rJava')
install.packages('rWeka')
install.packages('RWeka')
install.packages('RWekajars')
update.packages()
library(twitteR)
tweets <- searchTwitter('Singapore', n = 200)
tweets <- searchTwitter('Singapore MRT', n = 200)
tweets[[1:5\]]
tweets[[1:5]]
tweets[1:5]
length(tweets)
library(doMC)
registerDoMC(cores = 4)
foreach(i = 1:length(tweets), .combine='c', .inorder=F){tweets[[i]]$text}
tweets[[1]]$test
tweets[[1]]$text
foreach(i = 1:length(tweets), .combine='c', .inorder=F) %dopar% {tweets[[i]]$text}
tweet.data <- foreach(i = 1:length(tweets), .combine='c', .inorder=F) %dopar% {tweets[[i]]$text}
library(tm)
tweets <- Corpus(VectorSource(tweet.data))
summary(tweets)
tweets <- tm_map(tweets, tolower)
tweets <- tm_map(tweet.data, tolower)
tweets[1]
tweets
summary(tweets)
tweets[[1]]
tweets[[2]]
tweets[[3]]
tweets[[5]]
?tolower
tweets <- Corpus(VectorSource(tweet.data, encoding='ISO-8859-1'))
tweets <- tm_map(tweets, tolower)
?tm
??tm
help(package='tm')
x1 <- rnorm(100)
x2 <- rnorm(100)
x3 <- rnorm(100)
x4 <- rnorm(100)
ds1 <- data.frame(ctiy=rep(1, 100), x1=x1, x2=x2)
ds2 <- data.frame(ctiy=rep(2, 100), x1=x1, x3=x3, x4=x4)
merge(ds1, ds2, by = c('city', 'x1'))
merge(ds1, ds2, by.x = c('city', 'x1'), by.y = c('city', 'x1'))
merge(ds1, ds2, by.x = c('ctiy', 'x1'))
merge(ds1, ds2, by.x = c(x1'))
)
)]
)
)
)))))
]
,
x1 <- rnorm(100)
x2 <- rnorm(100)
x3 <- rnorm(100)
x4 <- rnorm(100)
ds1 <- data.frame(ctiy=rep(1, 100), x1=x1, x2=x2)
ds2 <- data.frame(ctiy=rep(2, 100), x1=x1, x3=x3, x4=x4)
merge(ds1, ds2, by = 'x1')
merge(ds1, ds2, by = c('x1', 'ctiy'))
merge(ds1, ds2, by = c('x1', 'ctiy'), all = T)
experiment <- data.frame(times = c(0,0,10,10,20,20,30,30), expval = c(1,1,2,2,3,3,4,4))
simul <- data.frame(times = c(0,10,20,30), simul = c(3,4,5,6))
experiment
simul
merge(experiment, simul, by = 'times')
merge(experiment, simul, by = 'times', all = T)
f1 <- c('C', 'A', 'T')
ifelse(f1=='C', 'C', 'NONC')
?model.matrix
model.matrix(factor(c('Yes', 'Yes', 'No'), levels=1:2))
y <- c('Yes', 'Yes', 'Yes', 'No')
y <- as.factor(y)
y
model.matrix(y)
model.matrix(y-1)
x <- c(2, 2, 5, 3, 6, 5, NA)
xf <- factor(x, levels = 2:6)
model.matrix(xf - 1)
model.matrix(xf)
model.matrix(as.numeric(xf))
?gl
dd <- data.frame(a = gl(3,4), b = gl(4,1,12))
dd
model.matrix(dd)
model.matrix(~ a, dd)
model.matrix(~ a+b, dd)
y <- factor(c("yes", 'yes', 'yes', 'no'))
y
model.matrix(~y, y)
model.matrix(~, y)
model.matrix(y)
y <- as.data.frame(y)
y
model.matrix(~ y, y)
iris
dummy <- model.matrix(Species ~ ., iris)
dummy
str(dummy)
dummy <- model.matrix(~ Species, iris)
dummy
dummy <- model.matrix(. ~ Species, iris)
summary(dummy)
attributres(dummy)
attributes(dummy)
dummy <- as.data.frame(dummy)
attributes(dummy)
names(dummy) <- labels(iris$Species)
names(dummy) <- levels(iris$Species)
summary(dummy)
str(dummy)
iris2 <- cbind(iris[1:4], dummy)
str(iris2)
head(iris2)
?order
df <- data.frame(x1=x1, x2=x2)
order(df)
df[order[df$x1, df$x2],]
df[df[order(df$x1, df$x2)],]
df[order(df$x1, df$x2),]
df <- data.frame(x1=x1, x2=x2, city = rep(c(1, 2), 50))
df[df[order(df$city, df$x2)],]
df[order(df$city, df$x2),]
aggreate(df, df$city, sum)
aggregate(df, df$city, sum)
summary(df$city)
aggregate(df, list(df$city), sum)
a <- NULL
attr(a, 'hello') <- 1
install.packages(c('RTextTools', 'topicmodels'))
library(RTextTools)
library(topicmodels)
data(NYTimes)
summary(NYTimes)
?create_matrix
matrix <- create_matrix(as.matrix(NYTimes[,c('Title', 'Subject')]), language = 'english', removeNumbers=T, stemWords=T, weighting=weightTf)
k <- length(unique(NYTimes$Topic.Code))
k
lda <- LDA(matrix, k)
summary(lda)
predict(lda, newdata = matrix)
attributes(lda)
str(lda)
install.packages('rpud')
?Dist
??Dist
library(ff)
library(ff)
library(caret)
library(rattle)
data(weather)
str(weather)
edit(weather)
describe(weather)
library(Hmisc)
describe(weather)
pie(table(weather$RainTomorrow))
text(table(weather$RainTomorrow))
pie(table(weather$RainToday))
xtabs(RainTomorrow ~ RainToday, data = weather)
xtabs(as.numeric(RainTomorrow) ~ as.numeric(RainToday), data = weather)
xtabs(~ RainTomorrow | RainToday, data = weather)
?xtabs
xtabs(~ RainTomorrow + RainToday, data = weather)
summary(weather)
describe(weather$RISK_MM)
risk_mm <- cut(weather$RISK_MM, quantile(weather$RISK_MM, probs=c(0, 0.10, 0.25, 0.50, 0.75, 1)))
risk_mm <- cut(weather$RISK_MM, breaks=quantile(weather$RISK_MM, probs=c(0, 0.10, 0.25, 0.50, 0.75, 1)))
quantile(weather$RISK_MM, probs=c(0, 0.10, 0.25, 0.50, 0.75, 1))
hist(weather$RISK_MM)
lines(density(weather$RISK_MM))
hist(weather$RISK_MM, probability=T)
lines(density(weather$RISK_MM))
risk_mm <- cut(weather$RISK_MM, breaks=c(0, 0.5, 1))
table(risk_mm, weather$RainTomorrow)
risk_mm <- cut(weather$RISK_MM, breaks=c(0, 0.5, 1, max(weather$RISK_MM)), include.lowest=T,right=T)
table(risk_mm, weather$RainTomorrow)
str(weather)
cor.cluster <- hclust(dist(cor(weather[, 3:23])))
cor.cluster <- hclust(dist(cor(weather[, 3:23], use='pairwise', method='pearson')))
numeric.attrs <- f
numeric.attrs <- Filter(function(c){is.numeric(weather[,c])}, names(weather))
numeric.attrs
cor.cluster <- hclust(dist(cor(weather[, numeric], use='pairwise', method='pearson')))
cor.cluster <- hclust(dist(cor(weather[, numeric.attrs], use='pairwise', method='pearson')))
plot(cor.cluster)
cor.cluster <- hclust(dist(cor(weather[, -numeric.attrs], use='pairwise', method='pearson')))
cor.cluster <- hclust(dist(cor(weather[, c('WindGustDir', 'RainToday', 'RainTomorrow')], use='pairwise', method='pearson')))
?cor
plot(weather[, numeric.attrs[1:5]], col= weather$RainTomorrow)
plot(weather, col= weather$RainTomorrow)
plot(weather[, 1:7], col= weather$RainTomorrow)
plot(weather[, c('WindSpeed9am', 'Sunshine', 'MinTemp', 'MaxTemp', 'Pressure3pm', 'Humidity9am', 'Cloud3pm')], col= weather$RainTomorrow)
plot(weather[, c('WindSpeed9am', 'Sunshine', 'MinTemp', 'MaxTemp', 'Pressure3pm', 'Humidity9am', 'Cloud3pm')], col= weather$RainTomorrow, pch = weather$RainToday)
plot(weather[, c('WindSpeed9am', 'Sunshine', 'MinTemp', 'MaxTemp', 'Pressure3pm', 'Humidity9am', 'Cloud3pm')], col= weather$RainTomorrow, pch = as.numeric(weather$RainTomorrow))
test.index <- sample(1:nrow(weather), nrow(weather)/5, replace = F)
weather.train <- weather[-test.index, ]
weather.test <- weather[test.index, ]
library(rpart)
weather.rpart <- rpart(RainTomorrow ~ RainToday + SunShine + Pressure3pm + Humidity9am, data = weather)
weather.rpart <- rpart(RainTomorrow ~ RainToday + Sunshine + Pressure3pm + Humidity9am, data = weather.strain)
weather.rpart <- rpart(RainTomorrow ~ RainToday + Sunshine + Pressure3pm + Humidity9am, data = weather.train)
plot(weather.rpart)
text(weather.rpart)
table(weather.test$RainTomorrow, predict(weather.rpart, newdata=weather.test))
summary(weather.test)
table(na.rm(weather.test$RainTomorrow), predict(weather.rpart, newdata=na.rm(weather.test)))
table(na.omit(weather.test$RainTomorrow), predict(weather.rpart, newdata=na.omit(weather.test)))
length((weather.test$RainTomorrow))
length(predict(weather.rpart, newdata=na.omit(weather.test)))
nrow(weather.test)
nrow(predict(weather.rpart, newdata=na.omit(weather.test)))
nrow(predict(weather.rpart, newdata=weather.test))
dim(predict(weather.rpart, newdata=weather.test))
dim(predict(weather.rpart, newdata=weather.test, type='response'))
predict.rpart
dim(predict(weather.rpart, newdata=weather.test, type='response'))
dim(predict(weather.rpart, newdata=weather.test, type='class'))
length(predict(weather.rpart, newdata=weather.test, type='class'))
table(weather.test$RainTomorrow, predict(weather.rpart, newdata=weather.test, type='class'))
table(weather.train$RainTomorrow, predict(weather.rpart, newdata=weather.train, type='class'))
table(predict(weather.rpart, newdata=weather.train, type='class'), weather.train$RainTomorrow)
?table
table(predict(weather.rpart, newdata=weather.train, type='class'), weather.train$RainTomorrow )
table(predict(weather.rpart, newdata=weather.train, type='class'))
table(weather.train$RainTomorrow, predict(weather.rpart, newdata=weather.train, type='class'))
weather.rpart$cptable
weather.rpart <- prune(weather.rpart, cp=0.02777778)
table(weather.train$RainTomorrow, predict(weather.rpart, newdata=weather.train, type='class'))
summary(weather.rpart)
weather.rpart <- rpart(RainTomorrow ~ RainToday + Sunshine + Pressure3pm + Humidity9am + Cloud3pm, data = weather.train)
weather.rpart$cptable
weather.rpart <- prune(weather.rpart, cp =  0.02777778 )
plot(weather.rpart)
text(weather.rpart)
weather.rpart <- rpart(RainTomorrow ~ RainToday + Sunshine + Pressure3pm + Humidity9am + Cloud3pm, data = weather.train)
plot(weather.rpart)
text(weather.rpart)
library(party)
weather.ctree <- ctree((RainTomorrow ~ RainToday + Sunshine + Pressure3pm + Humidity9am + Cloud3pm, data = weather.train))
weather.ctree <- ctree(RainTomorrow ~ RainToday + Sunshine + Pressure3pm + Humidity9am + Cloud3pm, data = weather.train)
plot(weather.ctree)
table(weather.test$RainTomorrow, predict(ctree, newdata=weather.test, type='class'))
table(weather.test$RainTomorrow, predict(weather.ctree, newdata=weather.test, type='class'))
table(weather.test$RainTomorrow, predict(weather.ctree, newdata=weather.test, type='response'))
table(weather.test$RainTomorrow, predict(weather.rpart, newdata=weather.test, type='class'))
table(weather.train$RainTomorrow, predict(weather.ctree, newdata=weather.train, type='response'))
summary(weather.rpart)
update.library()
update.packages()
library(Hmisc)
library(mice)
md.pattern(weather)
md.pattern(weather[,1:7])
md.pattern(weather[,1:8])
barplot(RainTomorrow~RainToday, data = weather)
?barplot
boxplot(Raintomorrow ~ RainToday, data = weather)
boxplot(RainTomorrow ~ RainToday, data = weather)
boxplot(RainTomorrow, data = weather)
boxplot(Pressure3pm~RainTomorrow, data = weather)
?cor
library(latticist)
install.packages('latticist')
library(latticist)
latticist(weather)
model.table(~RainTomorrow+RainToday, data = weather)
model.matrix(~RainTomorrow+RainToday, data = weather)
model.matrix(~RainTomorrow+RainToday, data = weather[1:10, ])
head(summary, n=10)
head(weather, n=10)
model.matrix(~RainTomorrow+RainToday, data = weather[1:10, ])
weather[1:10, c('RainToday', 'RainTomorrow')]
model.matrix(~RainTomorrow, data = weather[1:10, ])
dummy <- data.frame(Yes = as.numeric(RainTomorrow == 'Yes'), No = as.numeric(RainTomorrow == 'No'))
dummy <- with(weather, data.frame(Yes = as.numeric(RainTomorrow == 'Yes'), No = as.numeric(RainTomorrow == 'No')))
head(dummy)
?rpart
library(glmnet)
?glmnet
?rpart
summary(weather.rpart)
attributes(weather.rpart)
summary(weather.rpart$control)
print(weather.rpart$control)
weather.rpart <- rpart(RainTomorrow ~ RainToday + Sunshine + Pressure3pm + Humidity9am + Cloud3pm, data = weather.train, control=list(minsplit=10, minbucket=2))
plotcp(weather.rpart)
weather.rpart$cp
table(weather.test$RainTomorrow, predict(weather.rpart, newdata=weather.test, type='class'))
table(weather.train$RainTomorrow, predict(weather.rpart, newdata=weather.train, type='class'))
weather.rpart <- prune(weather.rpart, cp = 0.01851852)
table(weather.train$RainTomorrow, predict(weather.rpart, newdata=weather.train, type='class'))
table(weather.test$RainTomorrow, predict(weather.rpart, newdata=weather.test, type='class'))
plot(weather.rpaert)
plot(weather.rpart)
text(weather.rpart)
summary(weather.rpart)
print(weather.rpart)
weather.rpart <- prune(weather.rpart, cp = 0.01851852, parms=list(prior=c(0.5, 0.5)))
weather.rpart <- rpart(RainTomorrow ~ RainToday + Sunshine + Pressure3pm + Humidity9am + Cloud3pm, data = weather.train, parms = list(prior=c(0.5, 0.5)), control=list(minsplit=10, minbucket=2))
plot(weather.rpart)
text(weather.rpart)
cpplot(weather.rpart)
plotcp(weather.rpart)
printcp(weather.rpart)
table(weather.test$RainTomorrow, predict(weather.rpart, newdata=weather.test, type='class'))
table(weather.train$RainTomorrow, predict(weather.rpart, newdata=weather.train, type='class'))
weather.rpart <- prune(weather.rpart, cp = 0.011661)
plot(weather.rpart)
text(weather.rpart)
table(weather.test$RainTomorrow, predict(weather.rpart, newdata=weather.test, type='class'))
table(weather.train$RainTomorrow, predict(weather.rpart, newdata=weather.train, type='class'))
?ctree
install.packages('C5')
install.packages('C50')
library('RWeka')
library(C50)
update.packages()
library('fastcluster')
?hclust
?dist
library(bigmemory)
x <- big.matrix(100000, 3, init=0, type="double")
x[seq(1,100000,by=2),] <- rnorm(150000)
x[seq(2,100000,by=2),] <- rnorm(150000, 5, 1)
head(x)
ans <- bigkmeans(x, 1)
library(biganalytics)
?biganalytics
?bigmemory
version(bigmemory)
bigmemory.version
sessionInfo()
a <- 1L
a
class(a)
a <- 1
class(a)
setwd("~/workspace/fun_with_kaggle/event-recommendation/R")
library(randomForest)
library(foreach)
#library(Hmisc)
library(doMC)
library(rminer)
registerDoMC(cores = 4)
## common setting for train and test
rmse <- function(obs, pred) {return(sqrt(mean((as.numeric(obs)-as.numeric(pred))^2)))}
#{imputation (knn-3), na.roughfix, imputate}
imputation.method <- function(data){return (imputation(imethod='hotdeck',data,Value=3))}
## load test data
#test.set <- read.csv('../data/test_classifier.csv', header=T)
test.set <- read.csv('../data/test_private_classifier.csv', header=T)
## load train data
train.set <- read.csv('../data/train_classifier.csv', header=T)
## factorize
locale.levels <- union(levels(train.set$user_local), levels(test.set$user_local))
train.set$topic <- as.factor(train.set$topic)
test.set$topic <- as.factor(test.set$topic)
topic.levels <- union(levels(train.set$topic), levels(test.set$topic))
community.levels <- union(levels(train.set$user_community), levels(test.set$user_community))
train.set <- transform(train.set, user_locale=factor(user_locale, levels=locale.levels),
topic=factor(topic, levels=topic.levels, ordered=F),
user_community=factor(user_community, levels=community.levels, ordered=F))
test.set <- transform(test.set, user_locale=factor(user_locale, levels=locale.levels),
topic=factor(topic, levels=topic.levels, ordered=F),
user_community=factor(user_community, levels=community.levels, ordered=F))
## handle missing values - mainly in gender and age
## invalid ages >= 50
train.set$user_age <- ifelse(train.set$user_age <= 50,train.set$user_age, NA)
test.set$user_age <- ifelse(test.set$user_age <= 50,test.set$user_age, NA)
train.set <- imputation.method(train.set)
test.set <- imputation.method(test.set)
features <- -grep("^*(user|event)$", names(train.set)) #exclude non-use features
## as a regression, because interest_rank now is int
train.set_validation.index <- sample(nrow(train.set), nrow(train.set)/5, replace = F)
train.set_train <- train.set[-train.set_validation.index, features]
train.set_validation <- train.set[train.set_validation.index, features]
## build randomForest model in parallel
## use whole set to train
rf.model <- foreach(ntree=rep(400,8), .combine=combine, .packages="randomForest", .inorder=F) %dopar% {
randomForest(interest_rank~., data=train.set[,features],
ntree=ntree, importance=T, na.action=na.roughfix)
}
## validate the built model
print (rmse(train.set_validation$interest_rank,
predict(rf.model, newdata=train.set_validation, type='response')))
## predict on test data
test.prediction <- predict(rf.model, newdata=test.set, type='response')
test.set <- transform(test.set, interest_rank=test.prediction)
## write test to csv
write.csv(test.set, '../data/test_predictions.csv', row.names=F)
